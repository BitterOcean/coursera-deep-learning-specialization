# Improving Deep Neural Networks: Hyperparameter Tuning, Regularization and Optimization

**by** <a href="https://DeepLearning.AI/">DeepLearning.AI</a>

**Taught by**: <a href="https://www.coursera.org/instructor/andrewng">Andrew Ng</a>

**Student**: <a href="https://maryamsaeedmehr.github.io/">Maryam Saeidmehr</a>

## About this Course

In the second course of the Deep Learning Specialization, you will study the foundational concept of neural networks and deep learning. 
By the end, you will be familiar with the significant technological trends driving the rise of deep learning; build, train, and apply 
fully connected deep neural networks; implement efficient (vectorized) neural networks; identify key parameters in a neural network‚Äôs
architecture; and apply deep learning to your own applications.

The Deep Learning Specialization is our foundational program that will help you understand the capabilities, challenges, and consequences 
of deep learning and prepare you to participate in the development of leading-edge AI technology. It provides a pathway for you to gain 
the knowledge and skills to apply machine learning to your work, level up your technical career, and take the definitive step in the world of AI.

| Item | Description |
|---|---|
| üìì Basic Info  |  Course 2 of 5 in the <a href="https://www.coursera.org/specializations/deep-learning">Deep Learning Specialization</a>  |
| ‚öñÔ∏è Level  | Intermediate  |
| ‚è∞ Commitment  | At the rate of 5 hours a week, it takes roughly 5 weeks to finish each course in the Specialization.  |
| üî§ Language  | English, **Subtitles**: Chinese (Traditional), Arabic, French, Ukrainian, Portuguese (European), Chinese (Simplified), Italian, Portuguese (Brazilian), Vietnamese, Korean, German, Russian, Turkish, Spanish, Japanese</br> <a href="https://www.coursera.org/learn/neural-networks-deep-learning/home/info#">Volunteer to translate subtitles for this course</a>  |
| üßë‚Äçüéì How To Pass	Pass  |  all graded assignments to complete the course. |
| ‚≠ê User Ratings  | ![Rating](https://img.shields.io/badge/rating-4.9-brightgreen) |

## Syllabus

- <details open><summary><h2>Week 1</h2></summary>

  ### Practical Aspects of Deep Learning
    Discover and experiment with a variety of different initialization methods, apply L2 regularization and dropout to avoid model overfitting, then apply gradient checking to identify errors in a fraud detection model.

    <details>
      <summary>üìÇ 15 videos, 4 reading</summary>

  - Video: Train / Dev / Test sets
  - Video: Bias / Variance
  - Video: Basic Recipe for Machine Learning
  - App Item: [IMPORTANT] Have questions, issues or ideas? Join our Community!
  - Reading: Clarification about Upcoming Regularization Video
  - Video: Regularization
  - Video: Why Regularization Reduces Overfitting?
  - Video: Dropout Regularization
  - Reading: Clarification about Upcoming Understanding Dropout Video
  - Video: Understanding Dropout
  - Video: Other Regularization Methods
  - Video: Normalizing Inputs
  - Video: Vanishing / Exploding Gradients
  - Video: Weight Initialization for Deep Networks
  - Video: Numerical Approximation of Gradients
  - Video: Gradient Checking
  - Video: Gradient Checking Implementation Notes
  - Reading: Lecture Notes W1
  - Reading: (Optional) Downloading your Notebook, Downloading your Workspace and Refreshing your Workspace
  - Video: Yoshua Bengio Interview

    </details>

    üî¨**Graded**: Practical aspects of Deep Learning
    üî¨**Graded**: Initialization
    üî¨**Graded**: Regularization
    üî¨**Graded**: Gradient Checking

  </details>
---  
  - <details open><summary><h2>Week 2</h2></summary>

    ### Optimization Algorithms
      Develop your deep learning toolbox by adding more advanced optimizations, random minibatching, and learning rate decay scheduling to speed up your models.

      <details>
        <summary>üìÇ 11 videos, 3 readings</summary>

    - Video: Mini-batch Gradient Descent
    - Video: Understanding Mini-batch Gradient Descent
    - Video: Exponentially Weighted Averages
    - Video: Understanding Exponentially Weighted Averages
    - Video: Bias Correction in Exponentially Weighted Averages
    - Video: Gradient Descent with Momentum
    - Video: RMSprop
    - Reading: Clarification about Upcoming Adam Optimization Video
    - Video: Adam Optimization Algorithm
    - Reading: Clarification about Learning Rate Decay Video
    - Video: Learning Rate Decay
    - Video: The Problem of Local Optima
    - Reading: Lecture Notes W2
    - Video: Yuanqing Lin Interview

      </details>

      üî¨**Graded**: Optimization Algorithms
  
      üî¨**Graded**: Optimization Methods
  
    </details>
---
  - <details open><summary><h2>Week 3</h2></summary>

    ### Hyperparameter Tuning, Batch Normalization and Programming Frameworks
      Explore TensorFlow, a deep learning framework that allows you to build neural networks quickly and easily, then train a neural network on a TensorFlow dataset.

      <details>
        <summary>üìÇ 11 videos, 6 readings</summary>

    - Video: Tuning Process
    - Video: Using an Appropriate Scale to pick Hyperparameters
    - Video: Hyperparameters Tuning in Practice: Pandas vs. Caviar
    - Reading: Clarification about Upcoming Normalizing Activations in a Network Video
    - Video: Normalizing Activations in a Network
    - Video: Fitting Batch Norm into a Neural Network
    - Video: Why does Batch Norm work?
    - Video: Batch Norm at Test Time
    - Reading: Clarifications about Upcoming Softmax Video
    - Video: Softmax Regression
    - Video: Training a Softmax Classifier
    - Video: Deep Learning Frameworks
    - Video: TensorFlow
    - Reading: (Optional) Learn about Gradient Tape and More
    - Reading: Lecture Notes W3
    - Reading: References
    - Reading: Acknowledgments

      </details>

      üî¨**Graded**: Hyperparameter tuning, Batch Normalization, Programming Frameworks

      üî¨**Graded**: TensorFlow Introduction
  
    </details>


## Certificate

![Screenshot from 2023-08-24 18-41-04](https://github.com/BitterOcean/coursera-deep-learning-specialization/assets/60509979/9d71342f-bbf9-4e55-a526-04e04bebdb15)
    
  - ![IssuingOrganization](https://img.shields.io/badge/Issuing%20Organization-Coursera-informational)
  - ![IssueDate](https://img.shields.io/badge/Issue%20Date-Aug%202023-informational)
  - ![CredentialID](https://img.shields.io/badge/Credential%20ID-5GGFF6K26N65-informational)
  - <a href="https://www.coursera.org/account/accomplishments/verify/5GGFF6K26N65">![CredentialLink](https://img.shields.io/badge/Credential%20Link-https://www.coursera.org/account/accomplishments/certificate/XHL4HFTWRGYY-informational)</a>
  - <a href="https://github.com/BitterOcean/coursera-deep-learning-specialization/blob/main/Improving-Deep-Neural-Networks/Coursera%205GGFF6K26N65.pdf">![CertificateDownload](https://img.shields.io/badge/Certificate-Download%20PDF-informational)</a>
